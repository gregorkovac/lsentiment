{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eaf720f",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e31319b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gregor/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import src.preprocess_data as preprocess_data\n",
    "import importlib\n",
    "\n",
    "importlib.reload(preprocess_data)\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams['font.family'] = 'serif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d6235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52f4816",
   "metadata": {},
   "source": [
    "## Sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4860d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_140 = preprocess_data.read_sentiment140(os.path.join(DATA_PATH, \"sentiment140/training.1600000.processed.noemoticon.csv\"))\n",
    "\n",
    "df_140 = preprocess_data.introduce_neutral_sentiment(df_140)\n",
    "\n",
    "df_140 = preprocess_data.format_date(df_140)\n",
    "\n",
    "df_140 = df_140.drop(columns=[\"flag\"])\n",
    "\n",
    "df_140 = preprocess_data.clean_text(df_140)\n",
    "\n",
    "results_path = os.path.join(DATA_PATH, \"processed\")\n",
    "if not os.path.exists(results_path):\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "df_140.to_csv(os.path.join(DATA_PATH, \"processed/sentiment140.csv\"), header=True, index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd2aab9",
   "metadata": {},
   "source": [
    "## Stock Market Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e61ed9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2165/2165 [00:16<00:00, 131.79it/s]\n",
      "100%|██████████| 5884/5884 [01:11<00:00, 81.73it/s] \n"
     ]
    }
   ],
   "source": [
    "df_etfs, df_stocks = preprocess_data.read_stocks(os.path.join(DATA_PATH, \"stock_market_dataset/\"))\n",
    "\n",
    "df_etfs = preprocess_data.remove_rare_points(df_etfs)\n",
    "df_stocks = preprocess_data.remove_rare_points(df_stocks)\n",
    "\n",
    "df_etfs.to_csv(os.path.join(DATA_PATH, \"processed/etfs.csv\"), header=True, index=False, sep=\",\")\n",
    "df_stocks.to_csv(os.path.join(DATA_PATH, \"processed/stocks.csv\"), header=True, index=False, sep=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
