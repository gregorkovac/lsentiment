{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a15878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, \"..\")\n",
    "from models.LSenTiMent import LSenTiMent\n",
    "from src.train_test import get_dataloaders\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc3021bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LSenTiMent:\n\tMissing key(s) in state_dict: \"mlp.9.weight\", \"mlp.9.bias\", \"mlp.12.weight\", \"mlp.12.bias\", \"mlp.15.weight\", \"mlp.15.bias\", \"mlp.18.weight\", \"mlp.18.bias\", \"mlp.21.weight\", \"mlp.21.bias\". \n\tsize mismatch for mlp.6.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for mlp.6.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([64]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      1\u001b[39m model = LSenTiMent(\n\u001b[32m      2\u001b[39m     input_size=\u001b[32m1\u001b[39m,\n\u001b[32m      3\u001b[39m     hidden_size=\u001b[32m64\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     mlp_layers=\u001b[32m6\u001b[39m\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m state_dict = torch.load(\u001b[33m\"\u001b[39m\u001b[33m../models/model_no_sentiment.pt\u001b[39m\u001b[33m\"\u001b[39m, map_location=torch.device(\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/faks/deep_learning/project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2153\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2148\u001b[39m         error_msgs.insert(\n\u001b[32m   2149\u001b[39m             \u001b[32m0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m'\u001b[39m.format(\n\u001b[32m   2150\u001b[39m                 \u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[32m   2152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2153\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   2154\u001b[39m                        \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)))\n\u001b[32m   2155\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for LSenTiMent:\n\tMissing key(s) in state_dict: \"mlp.9.weight\", \"mlp.9.bias\", \"mlp.12.weight\", \"mlp.12.bias\", \"mlp.15.weight\", \"mlp.15.bias\", \"mlp.18.weight\", \"mlp.18.bias\", \"mlp.21.weight\", \"mlp.21.bias\". \n\tsize mismatch for mlp.6.weight: copying a param with shape torch.Size([1, 64]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for mlp.6.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([64])."
     ]
    }
   ],
   "source": [
    "model = LSenTiMent(\n",
    "    input_size=1,\n",
    "    hidden_size=64,\n",
    "    num_layers=1,\n",
    "    window_size=10,\n",
    "    sentiment=True,\n",
    "    dropout_rate=0.2,\n",
    "    mlp_hidden_size=64,\n",
    "    mlp_layers=6\n",
    ")\n",
    "\n",
    "state_dict = torch.load(\"../models/model_no_sentiment.pt\", map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f520b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/split\"\n",
    "\n",
    "with open(os.path.join(data_path, \"X_train.pkl\"), \"rb\") as f:\n",
    "        X_train = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(data_path, \"y_train.pkl\"), \"rb\") as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(data_path, \"X_val.pkl\"), \"rb\") as f:\n",
    "    X_val = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(data_path, \"y_val.pkl\"), \"rb\") as f:\n",
    "    y_val = pickle.load(f)\n",
    "\n",
    "X_train = torch.cat(X_train)\n",
    "y_train = torch.cat(y_train)\n",
    "\n",
    "X_val = torch.cat(X_val)\n",
    "y_val = torch.cat(y_val)\n",
    "\n",
    "train_dataloader, val_dataloader = get_dataloaders(X_train, y_train, X_val, y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8852c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a48c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "sys.path.insert(0, \".\")\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '.', 'finBERT')))\n",
    "import finBERT.finbert.finbert as finbert\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import nltk\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "def get_sentiment(text, model):\n",
    "    # with suppress_output():\n",
    "    result = finbert.predict(text, model, use_gpu=True)\n",
    "\n",
    "    return result[\"sentiment_score\"].mean()\n",
    "\n",
    "def get_sentiment_for_df(df):\n",
    "    print(\"Loading model...\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\",num_labels=3,cache_dir=None)\n",
    "\n",
    "    tqdm.pandas(desc=\"Analyzing sentiment\")\n",
    "    df[\"sentiment\"] = df[\"description\"].progress_apply(lambda x: get_sentiment(x, model))\n",
    "\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')\n",
    "    nltk.download('punkt_tab')\n",
    "\n",
    "    print(\"Reading data...\")\n",
    "\n",
    "    df = pd.read_csv(\"./financial_tweets.csv\")\n",
    "    df = df[[\"timestamp\", \"description\"]]\n",
    "    \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['timestamp'] = df['timestamp'].dt.date\n",
    "\n",
    "    df = df.dropna(subset=['description'])\n",
    "\n",
    "    # grouped_df = df.groupby('timestamp')['description'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "\n",
    "    df = get_sentiment_for_df(df)\n",
    "\n",
    "    df.to_csv(\"./financial_tweets_sentiments.csv\", index=False)\n",
    "\n",
    "    # df = get_sentiment_for_df(df)\n",
    "\n",
    "    # df.to_csv(\"./financial_tweets_sentiments.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
